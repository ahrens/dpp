#!/usr/bin/ksh

#
# CDDL HEADER START
#
# The contents of this file are subject to the terms of the
# Common Development and Distribution License (the "License").
# You may not use this file except in compliance with the License.
#
# You can obtain a copy of the license at usr/src/OPENSOLARIS.LICENSE
# or http://www.opensolaris.org/os/licensing.
# See the License for the specific language governing permissions
# and limitations under the License.
#
# When distributing Covered Code, include this CDDL HEADER in each
# file and include the License file at usr/src/OPENSOLARIS.LICENSE.
# If applicable, add the following below this CDDL HEADER, with the
# fields enclosed by brackets "[]" replaced with your own identifying
# information: Portions Copyright [yyyy] [name of copyright owner]
#
# CDDL HEADER END
#

#
# Copyright (c) 2015 by Delphix. All rights reserved.
#

. $STF_SUITE/include/libtest.shlib
. $STF_SUITE/tests/functional/redacted_send/redacted_send.cfg

typeset SIZE=512
typeset OPTS="-o recordsize=$SIZE -o checksum=sha256 -o compression=gzip"

#
# Create a consistent set of clones for the given snapshot, and name them.
#
function create_clones
{
	typeset snap=$1
	typeset vers=$2
	typeset fs=$(echo $snap | sed 's/@.*//')
	typeset pool=$(echo $snap | sed 's,/.*,,')

	log_must $ZFS clone $OPTS $snap $pool/hole_clone-$vers
	typeset mntpnt=$(get_prop mountpoint $pool/hole_clone-$vers)
	log_must $DD if=/dev/zero of=$mntpnt/f1 bs=$SIZE count=128 seek=128 conv=notrunc
	log_must $DD if=/dev/zero of=$mntpnt/f1 bs=$((4 * $SIZE)) count=16 seek=256 stride=4 conv=notrunc
	log_must $ZFS snapshot $pool/hole_clone-$vers@snap

	log_must $ZFS clone $OPTS $snap $pool/rm_clone1-$vers
	typeset mntpnt=$(get_prop mountpoint $pool/rm_clone1-$vers)
	log_must $RM $mntpnt/f1
	log_must $ZFS snapshot $pool/rm_clone1-$vers@snap

	log_must $ZFS clone $OPTS $snap $pool/int_clone-$vers
	log_must $ZFS snapshot $pool/int_clone-$vers@snap

	log_must $ZFS clone $OPTS $pool/int_clone-$vers@snap $pool/rm_clone2-$vers
	typeset mntpnt=$(get_prop mountpoint $pool/rm_clone2-$vers)
	log_must $RM $mntpnt/f4
	log_must $ZFS snapshot $pool/rm_clone2-$vers@snap

	log_must $ZFS clone $OPTS $pool/int_clone-$vers@snap $pool/write_clone-$vers
	typeset mntpnt=$(get_prop mountpoint $pool/write_clone-$vers)
	log_must $DD if=/dev/urandom of=$mntpnt/f3 bs=$SIZE count=128 seek=256 conv=notrunc
	log_must $DD if=/dev/urandom of=$mntpnt/f3 bs=$((4 * $SIZE)) count=16 stride=4 conv=notrunc
	log_must $ZFS snapshot $pool/write_clone-$vers@snap

	log_must $ZFS clone $OPTS $snap $pool/stride3_clone-$vers
	typeset mntpnt=$(get_prop mountpoint $pool/stride3_clone-$vers)
	log_must $DD if=/dev/urandom of=$mntpnt/f4 bs=$SIZE count=1365 stride=3 conv=notrunc
	log_must $ZFS snapshot $pool/stride3_clone-$vers@snap

	log_must $ZFS clone $OPTS $snap $pool/stride5_clone-$vers
	typeset mntpnt=$(get_prop mountpoint $pool/stride5_clone-$vers)
	log_must $DD if=/dev/urandom of=$mntpnt/f4 bs=$SIZE count=819 stride=5 conv=notrunc
	log_must $ZFS snapshot $pool/stride5_clone-$vers@snap

}

#
# Set up test model which includes various datasets
#
# Create a filesystem with 4 files; one with 64M of data, one missing
# file, one with holes mixed into the data, and one that is a 64M hole.
#
# $1 pool name
#
function setup_test_model
{
	log_must $ZFS create $OPTS $POOL/$FS
	log_must $DD if=/dev/urandom of=/$POOL/$FS/f1 bs=$SIZE count=4k
	log_must $TOUCH /$POOL/$FS/f2
	log_must $DD if=/dev/urandom of=/$POOL/$FS/f3 bs=$SIZE count=256 stride=16
	log_must $DD if=/dev/urandom of=/$POOL/$FS/f4 bs=$SIZE count=4k
	log_must $RM /$POOL/$FS/f2
	log_must $ZFS snapshot $POOL/$FS@snapA

	create_clones $POOL/$FS@snapA A

	log_must $DD if=/dev/urandom of=/$POOL/$FS/f1 bs=$SIZE count=128 stride=64

	log_must $ZFS snapshot $POOL/$FS@snapB
	create_clones $POOL/$FS@snapB B

	log_must $ZFS set recordsize=$(($SIZE * 32)) $POOL/$FS
	log_must $DD if=/dev/urandom of=/$POOL/$FS/f4 bs=$(($SIZE * 32)) count=64 stride=32

	log_must $ZFS snapshot $POOL/$FS@snapC
	create_clones $POOL/$FS@snapC C

	log_must $ZFS create $OPTS $POOL/$FS2
	for i in {1..256}; do
		count=$(random 100)
		stride=$(random 4)
		log_must $DD if=/dev/urandom of=/$POOL/$FS2/f$i bs=$SIZE count=$count \
		    stride=$stride 2>/dev/null
	done
	log_must $ZFS snapshot $POOL/$FS2@snap

	log_must $ZFS clone $OPTS $POOL/$FS2@snap $POOL/manyrm_clone
	for i in {32..96}; do
		log_must $RM /$POOL/manyrm_clone/f$i
	done
	log_must $ZFS snapshot $POOL/manyrm_clone@snap
	return 0
}

#
# Clean up the datasets in the pool.
#
# $1 pool name
#
function cleanup_pool
{
	typeset pool=$1
	log_must $ZFS destroy -Rf $pool/$FS
	log_must $ZFS destroy -Rf $pool/$FS2
	return 0
}

#
# Compare all the directores and files in two filesystems
#
# $1 source filesystem
# $2 destination filesystem
#
function cmp_ds_cont
{
	typeset src_fs=$1
	typeset dst_fs=$2

	typeset srcdir dstdir
	srcdir=$(get_prop mountpoint $src_fs)
	dstdir=$(get_prop mountpoint $dst_fs)

	$DIFF -r $srcdir $dstdir > /dev/null 2>&1
	$ECHO $?
}
